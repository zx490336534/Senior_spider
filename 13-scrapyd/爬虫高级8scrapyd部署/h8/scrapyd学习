笔记：
1、使用scrapyd和不使用scrapy的对比
简单来说，我们之前进行部署，我们是需要手动把这个 项目目录 拷贝到 目标服务器，
然后的话，在命令行执行 run.py
很地方不方便：
1.1、每次有更新，都需要重新拷贝
1.2、一旦同一个爬虫有多个不同的版本，必须在服务器上保持多份不同版本的目录，
每次在 命令行 中 执行命令时，是必须非常注意不要弄错版本

使用scrapyd之后，这些管理都交给它了，我们只需要执行一些简单的http命令就可以了


2、服务器环境
2.1 python 环境 需要自己安装
2.2 数据库得自己安装
2.3 scrapyd 也得自己安装


3、虚拟环境
在服务器和开发机都可以多套。。自己配置就好
然后也是可以配置环境

4、项目名 project
不是scrapy的项目名称，而是你部署项目到scrapyd服务器的时候，
    python scrapyd-deploy 127 -p taobao
上面这个命令中，后面的 -p taobao  这里指定的 taobao  这个名称
一般这个名称和scrapy项目名取一样的而已

5、字符串格式化
5.1  % 格式化
 '字符串格式化 %s ,测试' %  '变量'
5.2 format
'字符串格式化 {} ,测试'.format('变量')
5.3 字符串格式化常量
key = '变量'
str_test = f'字符串格式化 {key} ,测试'


6、requests 提交 参数
有3种：
data = {
    'k1': 'v1',
    'k2': 'v2'
}
1、params = data ，参数会提交到 url 后加 ?
2、data = data  参数提交到 http 请求的 body中，格式是 k1=v1&k2=v2
3、json = data  参数提交到 http 请求的 body中， 格式是 json字符串，{'k1':'v1','k2':'v2'}

7、scrapy项目部署和数据库没关系的，只要能够访问到，就可以了


8、scrapyd启动的项目，两种方式关闭
8.1 通过cancel.json 命令
8.2 通过系统 kill 进程