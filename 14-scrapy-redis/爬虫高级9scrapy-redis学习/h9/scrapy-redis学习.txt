1、建立一个scrapy项目，通过 scrapy startproject project_name
2、pycharm 打开 第一步新建的项目
3、编写 item
4、编写 自己的 spider ，
    要启用从 redis 中读取 项目名:start_urls 这个功能，
    spider类 要 继承 scrapy_redis.spiders.RedisCrawlSpider 或scrapy_redis.spiders.RedisSpider
5、修改 settings 配置
6、启动redis数据库
7、在redis中写入 project_name:start_urls
7、写一个 run.py ，进行本地测试
8、测试成功后，需要手动写一个将 item  从 redis 转移到 mongodb 的模块

9、测试功能，开始部署
10、拷贝 scrapyd-deploy 到 项目根目录
11、修改 scrapy.cfg
12、启动目标服务器的scrapyd
13、通过在cmd窗口中，切换到项目根目录，通过如下命令部署：
    python scrapyd-deploy 127 -p dingdian
14、通过自己写的 scrapyd 控制方法，启动、停止项目


注意事项：
1、scrapy_redis.pipelines.RedisPipeline
    这个 item 的 pipeline，在配置中，他是最后一个就行

2、redis 不可以作为数据的永久持久化数据库！！！！！！
    使用scrapy-redis，可以把item持久化到 redis中，但是一定自己写程序把item从redis导入到其他的
    普通数据库中，如mongodb、mysql等